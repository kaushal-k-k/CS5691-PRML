# -*- coding: utf-8 -*-
"""PRML_assignment2_question1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tBf3hHllqE8dmyBTyZcZN8a3upkXoV4T
"""

from google.colab import drive
drive.mount('/content/drive')

import glob
import numpy as np
import math
import pandas as pd
import random
import scipy.linalg as la
import matplotlib.pyplot as plt
import cv2

def load_data(path):
  d= pd.read_csv(path,header=None)
  return d

def generate(K,S):
  if(S==1):
    return np.random.dirichlet(np.ones(K),size=1)[0],[random.random() for i in range(K)],[random.randint(1,K) for i in range(K)]
  else:
    return np.random.dirichlet(np.ones(K),size=1)[0],[random.random() for i in range(K)],[random.random() for i in range(K)]

data=load_data('drive/My Drive/prml assignment/assignment 2/question 1/A2Q1Data.csv')
data=list(data[0])
K=4

print(data)

"""# a"""

def EM1(iteration):
  # initialize theta
  
  pl,p,_=generate(K,1)
  # print(pl,sum(pl))
  n=len(data)
  # print(p)
  l=[]
  # for i in range(n):
  #   t=[]
  #   for j in range(K):
  #     t.append(0)
  #   l.append(t)

  logl=[]

  for i in range(iteration):
    l=[]
    for j in data:

      t=[ p[k]**j * (1-p[k])**(1-j) * pl[k] for k in range(K)]
      t=np.array(t)/sum(t)
      l.append(t)
    
    for k in range(K):
      t=0
      t1=0
      for j in range(n):
        t+=l[j][k]
        t1+=l[j][k]*data[j]

      p[k]=t1/t
      pl[k]=t/n

    tt=0
    tt3=[]
    for j in range(n):
      t=[ l[j][k] * math.log(p[k]**data[j] * (1-p[k])**(1-data[j]) * pl[k] / l[j][k]) for k in range(K)]
      tt+=sum(t)
      tt3.append(t.index(max(t)))

    logl.append(tt)

  return logl,p,pl,tt3

result=[]
tp=[]
tpl=[]
ass1=[]
for i in range(100):
  a,b,c,d=EM1(10)
  result.append(a)
  tp.append(b)
  tpl.append(c)
  ass1.append(d)

result=np.average(result,axis=0)

plt.figure(figsize=(5,7))
plt.plot(result)
plt.xlabel("x-axis/no of iterations")
plt.ylabel("y-axis/average of modified log likihood over 100 random initialization")
plt.savefig("be.png",dpi=300)
# print(ass1[-1])
# print(tp[-1])
# print(ass1[-3])
# print(tp[-2],tpl[-2])
# print(data)

"""# b

"""

def EM2(iteration):
  # initialize theta
  
  pl,p,s=generate(K,2)
  # print(pl,sum(pl))
  n=len(data)
  # print(p)
  l=[]
  logl=[]
  # print(p)
  for i in range(iteration):
    l=[]
    for j in data:
      t=[]
      for k in range(K):
        if(s[k] == 0):
          t.append(0)
        else:
          m=-1 * ((j-p[k])**2) / (2 * s[k])
          # print(p[k],s[k],m)
          m=math.exp(m)
          m=m*pl[k]
          t.append(m)
      if(sum(t)!=0):
        t=np.array(t)/sum(t)
      else:
        t=np.array(t)

      l.append(t)
    
    for k in range(K):
      # for mean and pik
      t=0
      t1=0
      for j in range(n):
        t+=l[j][k]
        t1+=l[j][k]*data[j]

      if(t!=0):
        p[k]=t1/t
      else:
        p[k]=0

      pl[k]=t/n

      # for sigma square
      t2=0
      for j in range(n):
        t2 += l[j][k] * (data[j] - p[k])**2
      if(t!=0):
        s[k] = t2/t
      else:
        s[k]=0

    # for loglikelyhood
    tt=0
    tt3=[]
    for j in range(n):
      t=[]
      for k in range(K):
        if(s[k] == 0):
          t.append(0)
        else:
          m=-1 * ((data[j]-p[k])**2) / (2 * s[k])
          m=math.exp(m)
          m=m*pl[k]/l[j][k]
          if(m!=0):
            t.append(l[j][k]*math.log(m))

        # if(sum(t) != 0):
        #   tt+=math.log(sum(t))
      tt+=sum(t)
      tt3.append(t.index(max(t)))

    logl.append(tt)

  return logl,p,pl,s,tt3

result2=[]
tp2=[]
tpl2=[]
s2=[]
ass2=[]
for i in range(100):
  # print(i)
  a,b,c,d,e=EM2(50)
  result2.append(a)
  tp2.append(b)
  tpl2.append(c)
  s2.append(d)
  ass2.append(e)

result2=np.average(result2,axis=0)

plt.figure(figsize=(5,7))
plt.xlabel("x-axis/no of iterations")
plt.ylabel("y-axis/average of modified log likihood over 100 random initialization")
plt.plot(result2)
plt.savefig("gauss.png",dpi=300)

plt.figure(figsize=(5,7))
plt.plot(result2,label="gaussian-mixture")
plt.plot(result,label="bernoulli-mixture")
plt.xlabel("x-axis/no of iterations")
plt.ylabel("y-axis/average of log likihood over 100 random initialization")
plt.legend()
plt.savefig("compare.png",dpi=300)
# print(ass2[18])

# print(tp2[-1],s2[-1])
# print(ass2[-3])
# print(data)

"""# c

"""

def k_means(data):
  
  n=len(data)
  z=[ random.randint(0,K-1) for i in range(n)]
  flag=1
  objective=[]

  while flag:
    flag=0
    p=[0 for i in range(K)]
    l=[0 for i in range(K)]

    for i in range(n):
      p[z[i]]+=data[i]
      l[z[i]]+=1

    u=[ (p[i])/(l[i]+1) for i in range(K)]
   
    # print(z)
    # print(u)
    tt3=4
    for i in range(n):
      dist=[(data[i]-j)**2 for j in u ]
      t=dist.index(min(dist))
      # print(t,z[i])
      if t != z[i]:
        flag=1
       
      
      z[i]=t

    objective.append(sum([ (data[i]-u[z[i]])**2 for i in range(n)]))
  
  return objective,z,u

c,ass,mean=k_means(data)
plt.plot(c)
plt.xlabel("x-axis/no of iterations")
plt.ylabel("y-axis/ objective of k-means")
plt.savefig("kmeans.png",dpi=300)
print(ass)
# print(len(c))
print(mean)
print(data)